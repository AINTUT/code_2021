{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Exercise 2] Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv49axWeylsB"
      },
      "source": [
        "This notebook is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/).\n",
        "\n",
        "Author: 蘇嘉冠\n",
        "\n",
        "Contributors: 鄭宇伸, 喬彥翔"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0_QjevL_F5"
      },
      "source": [
        "# [Exercise 2] Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e75HmxuUENW8"
      },
      "source": [
        "## 展示題：房價預測（單變數版本）\n",
        "\n",
        "我們蒐集到了波士頓郊區的房價資料集（[來源](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/?C=N;O=D)），想要從某城鎮的一個 feature，來預測該城鎮自用住宅的房價中位數（`MEDV`）。\n",
        "\n",
        "我們將這個資料集的 csv 檔讀入至一個 pandas 的 DataFrame：`df`。資料的各個 column 的意義如下：\n",
        "- `CRIM`：某城鎮的人均犯罪率\n",
        "- `ZN`：「超過 25,000 平方呎的住宅用地區塊」所佔的比例\n",
        "- `INDUS`：某城鎮「非零售的商業用地」比例（英畝）\n",
        "- `NOX`：一氧化氮濃度（以 10 ppm 為單位）\n",
        "- `RM`：平均每戶有幾個房間\n",
        "- `AGE`： 1940 年之前所建的房屋，屋主自用的比例\n",
        "- `DIS`：到波士頓五個就業服務中心的（加權）距離\n",
        "- `RAD`：使用高速公路的方便性 / 可達性指數\n",
        "- `TAX`：「總價 / 房屋稅」的比例（單位：10,000 美金）\n",
        "- `PTRATIO`：某城鎮的「生 / 師」比\n",
        "- `MEDV`：自用住宅的房價中位數（單位：1,000 美金）\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJA285HdE5sV"
      },
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn mlxtend==0.18.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPXEltR9R6bR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mlxtend.plotting import scatterplotmatrix\n",
        "from mlxtend.plotting import heatmap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-rM4vVFkR7y"
      },
      "source": [
        "### Exploratory Data Analysis (EDA)\n",
        "\n",
        "在開使訓練一個機器學習模型之前，一個很重要的工作是做 Exploratory Data Analysis (EDA)，透過視覺化的方式來了解資料的分佈、feature 之間的關係等。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qFffL07R8k5"
      },
      "source": [
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/AINTUT/code_2021/main/datasets/\"\n",
        "    \"house_pricing.csv\",\n",
        ")\n",
        "\n",
        "print(df.head())\n",
        "print(list(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNj-jA_kmAI8"
      },
      "source": [
        "columns = [\n",
        "    \"CRIM\",\n",
        "    \"NOX\",\n",
        "    \"RM\",\n",
        "    \"DIS\",\n",
        "    \"TAX\",\n",
        "    \"PTRATIO\",\n",
        "    \"MEDV\",\n",
        "]\n",
        "\n",
        "scatterplotmatrix(\n",
        "    df[columns].to_numpy(),\n",
        "    figsize=(10, 8),\n",
        "    names=columns,\n",
        "    alpha=0.5,\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCrBim6joi1T"
      },
      "source": [
        "cm = np.corrcoef(df[columns].to_numpy().T)\n",
        "hm = heatmap(cm, row_names=columns, column_names=columns)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZELkhwY1TYrO"
      },
      "source": [
        "df.plot.scatter(x=\"RM\", y=\"MEDV\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0yNyZjzsAAt"
      },
      "source": [
        "x_data = df[[\"RM\"]].to_numpy()\n",
        "y_data = df[\"MEDV\"].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_0lLZuiq0_w"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "選定 feature 後，我們將對資料做以下處理：\n",
        "1. 將資料分割成 training data 與 testing data\n",
        "2. 用 standardization 對資料做 feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxHbYlPgsqq6"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data,\n",
        "    y_data,\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioEQ8QANVy6J"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_std = scaler.fit_transform(x_train)\n",
        "x_test_std = scaler.transform(x_test)\n",
        "\n",
        "print(x_train[:10])\n",
        "print(x_train_std[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83AzyzUnvAoS"
      },
      "source": [
        "### Training\n",
        "\n",
        "開始我們訓練模型的流程，主要包含以下步驟：\n",
        "1. 定義 function set：$f(x) = b + w_{1}x_{1}$\n",
        "2. 定義 loss function：$L(b, w_{1}) = \\frac{1}{2}\\sum_{i=1}^{n}(\\hat{y}^{(i)} - (b + w_{1}{x}^{(i)}_{1}))^2$\n",
        "3. 學習，使用 Gradient Descent 來找最佳的 function：$f^{*}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Pox8MGxq7_"
      },
      "source": [
        "def predict(x, weights):\n",
        "    return np.dot(x, weights[1:]) + weights[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vRU307AzgeR"
      },
      "source": [
        "def calculate_loss(y_gt, y_pred):\n",
        "    loss = ((y_gt - y_pred) ** 2).sum() / 2.0\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIJLbj3HzioA"
      },
      "source": [
        "def fit(x_train, y_train, epoches, learning_rate):\n",
        "    weights = np.zeros(x_train.shape[1] + 1)\n",
        "    losses = []\n",
        "\n",
        "    for _ in range(epoches):\n",
        "        y_pred = predict(x_train, weights)\n",
        "\n",
        "        diff = y_train - y_pred\n",
        "        weights[0] = weights[0] - learning_rate * -diff.sum()\n",
        "        weights[1:] = weights[1:] - learning_rate * -x_train.T.dot(diff)\n",
        "\n",
        "        losses.append(calculate_loss(y_train, y_pred))\n",
        "\n",
        "    return weights, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPqfCd-XVfhi"
      },
      "source": [
        "epoches = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "weights, losses = fit(x_train_std, y_train, epoches, learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld8BmR8LVr1m"
      },
      "source": [
        "plt.plot(range(1, epoches + 1), losses)\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snCXX6gTk45j"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "來看一下我們的訓練成果！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6ZsyOBjjd9E"
      },
      "source": [
        "def reg_plot(x, y_gt, y_pred):\n",
        "    plt.scatter(x, y_gt, c=\"steelblue\", edgecolor=\"white\")\n",
        "    plt.plot(x, y_pred, c=\"black\")\n",
        "\n",
        "    plt.xlabel(\"RM\")\n",
        "    plt.ylabel(\"MEDV\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll7-tGlQjmMw"
      },
      "source": [
        "y_pred = [predict(x, weights) for x in x_train_std]\n",
        "\n",
        "reg_plot(x_train, y_train, y_pred)\n",
        "\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "\n",
        "print(\"MSE of Training Data: {}\".format(mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQPNT5rKqDw"
      },
      "source": [
        "y_pred = [predict(x, weights) for x in x_test_std]\n",
        "\n",
        "reg_plot(x_test, y_test, y_pred)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"MSE of Testing Data: {}\".format(mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG2emDCCk_Fh"
      },
      "source": [
        "### 改用 Scikit-Learn 做 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEGf4fzalFRp"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH_fGdEbnykI"
      },
      "source": [
        "y_pred = lr.predict(x_train)\n",
        "\n",
        "reg_plot(x_train, y_train, y_pred)\n",
        "\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "\n",
        "print(\"MSE of Training Data: {}\".format(mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kth7pi9XoDJO"
      },
      "source": [
        "y_pred = lr.predict(x_test)\n",
        "\n",
        "reg_plot(x_test, y_test, y_pred)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"MSE of Testing Data: {}\".format(mse))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}